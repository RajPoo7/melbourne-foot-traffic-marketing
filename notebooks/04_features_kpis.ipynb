{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49017d16",
   "metadata": {},
   "source": [
    "# 04 — Feature Engineering & KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d121048-7970-4c22-8d68-8efa63b0ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/poojithraj/Documents/melbourne-foot-traffic-marketing\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path.cwd().parents[0]                    # repo root (adjust if needed)\n",
    "INTERIM = ROOT / \"data\" / \"interim\"\n",
    "AN      = ROOT / \"analytics\" / \"looker_studio_datasources\"\n",
    "AN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "assert (ROOT/\".git\").exists(), \"Not at repo root—adjust ROOT so ROOT/'.git' exists.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c290a72-6d2a-4487-b4f4-ab6b99f8cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64040, 7) 2025-03-01 00:00:00+11:00 2025-03-31 23:00:00+11:00\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INTERIM / \"counts_weather_hourly.csv\", parse_dates=[\"date_time\"])\n",
    "need = {\"sensor_id\",\"hourly_counts\",\"temperature_2m\",\"precipitation\"}\n",
    "missing = need - set(df.columns)\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "print(df.shape, df.date_time.min(), df.date_time.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3bc0ab-9601-4e8c-a8e2-c0a9630038e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 64040 | dates: 2025-03-01 00:00:00+11:00 → 2025-03-31 23:00:00+11:00\n"
     ]
    }
   ],
   "source": [
    "df[\"date\"]       = df[\"date_time\"].dt.date\n",
    "df[\"hour\"]       = df[\"date_time\"].dt.hour\n",
    "df[\"dow\"]        = df[\"date_time\"].dt.dayofweek            # 0=Mon\n",
    "df[\"dow_name\"]   = df[\"date_time\"].dt.day_name()\n",
    "df[\"is_weekend\"] = df[\"dow\"].isin([5,6])\n",
    "df[\"month\"]      = df[\"date_time\"].dt.month\n",
    "\n",
    "df[\"rain_mm\"]    = pd.to_numeric(df[\"precipitation\"], errors=\"coerce\").fillna(0)\n",
    "df[\"rain_flag\"]  = (df[\"rain_mm\"] > 0).astype(int)\n",
    "\n",
    "df[\"temp_c\"]     = pd.to_numeric(df[\"temperature_2m\"], errors=\"coerce\")\n",
    "bins   = [-100, 10, 18, 24, 30, 100]\n",
    "labels = [\"<10°C\", \"10–18°C\", \"18–24°C\", \"24–30°C\", \">30°C\"]\n",
    "df[\"temp_bin\"]   = pd.cut(df[\"temp_c\"], bins=bins, labels=labels)\n",
    "\n",
    "print(\"rows:\", len(df), \"| dates:\", df.date_time.min(), \"→\", df.date_time.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8169854e-e118-4bec-b170-e7ba4d1e28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = (df.groupby([\"sensor_id\",\"date\"], as_index=False)\n",
    "           .agg(hourly_total=(\"hourly_counts\",\"sum\")))\n",
    "daily.head()\n",
    "daily.to_csv(AN/\"daily_totals.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f096672-aac6-4332-911e-a74445a5524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = (df.groupby([\"sensor_id\",\"dow_name\",\"hour\"], as_index=False)\n",
    "             .agg(median_count=(\"hourly_counts\",\"median\"),\n",
    "                  mean_count=(\"hourly_counts\",\"mean\"),\n",
    "                  samples=(\"hourly_counts\",\"size\")))\n",
    "heatmap.head()\n",
    "heatmap.to_csv(AN/\"heatmap_weekday_hour.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79af7f7-130a-4096-99ef-c9ee2fc434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = (heatmap.sort_values([\"sensor_id\",\"median_count\"], ascending=[True,False])\n",
    "                 .groupby(\"sensor_id\")\n",
    "                 .head(3)\n",
    "                 .assign(rank=lambda d: d.groupby(\"sensor_id\").cumcount()+1))\n",
    "power.head()\n",
    "power.to_csv(AN/\"power_hours_top3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc83baa-2587-4400-b83d-ebf3d8b10e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = (df.groupby([\"sensor_id\",\"rain_flag\"], as_index=False)\n",
    "          .agg(med=(\"hourly_counts\",\"median\")))\n",
    "pivot = (rain.pivot(index=\"sensor_id\", columns=\"rain_flag\", values=\"med\")\n",
    "             .rename(columns={0:\"med_no_rain\",1:\"med_rain\"})\n",
    "             .reset_index())\n",
    "pivot[\"rain_delta_pct\"] = (pivot[\"med_rain\"] - pivot[\"med_no_rain\"]) / pivot[\"med_no_rain\"] * 100\n",
    "pivot.head()\n",
    "pivot.to_csv(AN/\"rain_uplift_by_sensor.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c66c488-3a9a-4e13-8217-5e664f851dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = df[[\"sensor_id\",\"date_time\",\"hourly_counts\",\"rain_flag\",\"temp_c\",\"temp_bin\"]].copy()\n",
    "hourly.head()\n",
    "hourly.to_csv(AN/\"counts_by_hour.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fdb360-c85a-4268-8bb2-7cc59c5b1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = pd.read_csv(INTERIM/\"sensor_locations_clean.csv\")\n",
    "look = sensors[[\"sensor_id\",\"sensor_name\"]].drop_duplicates()\n",
    "look.to_csv(AN/\"sensors_lookup.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f8ea44-8f98-4ed1-9278-5c4c85693c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[31mM\u001b[m notebooks/02_clean_join_geo.ipynb\n",
      " \u001b[31mM\u001b[m notebooks/03_weather_merge.ipynb\n",
      " \u001b[31mM\u001b[m notebooks/04_features_kpis.ipynb\n",
      "\u001b[31m??\u001b[m Miniforge3-MacOSX-arm64.sh\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/counts_by_hour.csv\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/daily_totals.csv\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/heatmap_weekday_hour.csv\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/power_hours_top3.csv\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/rain_uplift_by_sensor.csv\n",
      "\u001b[31m??\u001b[m analytics/looker_studio_datasources/sensors_lookup.csv\n",
      "fatal: pathspec '/Users/poojithraj/Documents/melbourne-foot-traffic-marketing/analytics/looker_studio_datasources/temp_uplift_by_sensor.csv' did not match any files\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   notebooks/02_clean_join_geo.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   notebooks/03_weather_merge.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   notebooks/04_features_kpis.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mMiniforge3-MacOSX-arm64.sh\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/counts_by_hour.csv\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/daily_totals.csv\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/heatmap_weekday_hour.csv\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/power_hours_top3.csv\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/rain_uplift_by_sensor.csv\u001b[m\n",
      "\t\u001b[31manalytics/looker_studio_datasources/sensors_lookup.csv\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git -C \"{ROOT}\" status -s\n",
    "\n",
    "!git -C \"{ROOT}\" add \\\n",
    "    notebooks/04_features_kpis.ipynb \\\n",
    "    \"{AN}/daily_totals.csv\" \\\n",
    "    \"{AN}/heatmap_weekday_hour.csv\" \\\n",
    "    \"{AN}/power_hours_top3.csv\" \\\n",
    "    \"{AN}/rain_uplift_by_sensor.csv\" \\\n",
    "    \"{AN}/temp_uplift_by_sensor.csv\" \\\n",
    "    \"{AN}/counts_by_hour.csv\" \\\n",
    "    \"{AN}/sensors_lookup.csv\"\n",
    "\n",
    "!git -C \"{ROOT}\" commit -m \"04: features & KPIs — heatmap, power hours, rain/temp effects; exports for Looker Studio\"\n",
    "!git -C \"{ROOT}\" push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535dab78-6b35-4cdb-93ed-15587b59d846",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (593271782.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnotebooks/02_clean_join_geo.ipynb \\\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "git add analytics/looker_studio_datasources/*.csv \\\n",
    "        notebooks/02_clean_join_geo.ipynb \\\n",
    "        notebooks/03_weather_merge.ipynb \\\n",
    "        notebooks/04_features_kpis.ipynb\n",
    "\n",
    "git commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\n",
    "git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054b4188-f7f6-4e1b-9724-7a1fdb7b6b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " M 02_clean_join_geo.ipynb\n",
      " M 03_weather_merge.ipynb\n",
      " M 04_features_kpis.ipynb\n",
      "?? ../Miniforge3-MacOSX-arm64.sh\n",
      "?? ../analytics/looker_studio_datasources/counts_by_hour.csv\n",
      "?? ../analytics/looker_studio_datasources/daily_totals.csv\n",
      "?? ../analytics/looker_studio_datasources/heatmap_weekday_hour.csv\n",
      "?? ../analytics/looker_studio_datasources/power_hours_top3.csv\n",
      "?? ../analytics/looker_studio_datasources/rain_uplift_by_sensor.csv\n",
      "?? ../analytics/looker_studio_datasources/sensors_lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'analytics/looker_studio_datasources/daily_totals.csv' did not match any files\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'set -euo pipefail\\n\\n# 1) See what\\'s untracked/modified\\ngit status -s\\n\\n# 2) Stage ONLY the files that actually exist\\ngit add analytics/looker_studio_datasources/daily_totals.csv \\\\\\n        analytics/looker_studio_datasources/heatmap_weekday_hour.csv \\\\\\n        analytics/looker_studio_datasources/power_hours_top3.csv \\\\\\n        analytics/looker_studio_datasources/rain_uplift_by_sensor.csv \\\\\\n        analytics/looker_studio_datasources/counts_by_hour.csv \\\\\\n        analytics/looker_studio_datasources/sensors_lookup.csv \\\\\\n        notebooks/02_clean_join_geo.ipynb \\\\\\n        notebooks/03_weather_merge.ipynb \\\\\\n        notebooks/04_features_kpis.ipynb\\n\\n# 3) Commit\\ngit commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\\n\\n# 4) Push\\ngit push origin main\\n'' returned non-zero exit status 128.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mset -euo pipefail\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# 1) See what\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43ms untracked/modified\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgit status -s\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# 2) Stage ONLY the files that actually exist\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgit add analytics/looker_studio_datasources/daily_totals.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        analytics/looker_studio_datasources/heatmap_weekday_hour.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        analytics/looker_studio_datasources/power_hours_top3.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        analytics/looker_studio_datasources/rain_uplift_by_sensor.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        analytics/looker_studio_datasources/counts_by_hour.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        analytics/looker_studio_datasources/sensors_lookup.csv \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        notebooks/02_clean_join_geo.ipynb \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        notebooks/03_weather_merge.ipynb \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        notebooks/04_features_kpis.ipynb\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# 3) Commit\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgit commit -m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# 4) Push\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgit push origin main\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/melb_foot_traffic/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/melb_foot_traffic/lib/python3.11/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/melb_foot_traffic/lib/python3.11/site-packages/IPython/core/magics/script.py:348\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    347\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b'set -euo pipefail\\n\\n# 1) See what\\'s untracked/modified\\ngit status -s\\n\\n# 2) Stage ONLY the files that actually exist\\ngit add analytics/looker_studio_datasources/daily_totals.csv \\\\\\n        analytics/looker_studio_datasources/heatmap_weekday_hour.csv \\\\\\n        analytics/looker_studio_datasources/power_hours_top3.csv \\\\\\n        analytics/looker_studio_datasources/rain_uplift_by_sensor.csv \\\\\\n        analytics/looker_studio_datasources/counts_by_hour.csv \\\\\\n        analytics/looker_studio_datasources/sensors_lookup.csv \\\\\\n        notebooks/02_clean_join_geo.ipynb \\\\\\n        notebooks/03_weather_merge.ipynb \\\\\\n        notebooks/04_features_kpis.ipynb\\n\\n# 3) Commit\\ngit commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\\n\\n# 4) Push\\ngit push origin main\\n'' returned non-zero exit status 128."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "# 1) See what's untracked/modified\n",
    "git status -s\n",
    "\n",
    "# 2) Stage ONLY the files that actually exist\n",
    "git add analytics/looker_studio_datasources/daily_totals.csv \\\n",
    "        analytics/looker_studio_datasources/heatmap_weekday_hour.csv \\\n",
    "        analytics/looker_studio_datasources/power_hours_top3.csv \\\n",
    "        analytics/looker_studio_datasources/rain_uplift_by_sensor.csv \\\n",
    "        analytics/looker_studio_datasources/counts_by_hour.csv \\\n",
    "        analytics/looker_studio_datasources/sensors_lookup.csv \\\n",
    "        notebooks/02_clean_join_geo.ipynb \\\n",
    "        notebooks/03_weather_merge.ipynb \\\n",
    "        notebooks/04_features_kpis.ipynb\n",
    "\n",
    "# 3) Commit\n",
    "git commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\n",
    "\n",
    "# 4) Push\n",
    "git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bf717e9-b1e2-469c-9c5c-8d30bd3f897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/daily_totals.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/heatmap_weekday_hour.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/power_hours_top3.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/rain_uplift_by_sensor.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/counts_by_hour.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/analytics/looker_studio_datasources/': No such file or directory\n",
      "fatal: pathspec 'analytics/looker_studio_datasources/sensors_lookup.csv' did not match any files\n",
      "warning: could not open directory 'notebooks/notebooks/': No such file or directory\n",
      "fatal: pathspec 'notebooks/02_clean_join_geo.ipynb' did not match any files\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   02_clean_join_geo.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   03_weather_merge.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   04_features_kpis.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m../Miniforge3-MacOSX-arm64.sh\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/counts_by_hour.csv\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/daily_totals.csv\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/heatmap_weekday_hour.csv\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/power_hours_top3.csv\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/rain_uplift_by_sensor.csv\u001b[m\n",
      "\t\u001b[31m../analytics/looker_studio_datasources/sensors_lookup.csv\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add analytics/looker_studio_datasources/daily_totals.csv\n",
    "!git add analytics/looker_studio_datasources/heatmap_weekday_hour.csv\n",
    "!git add analytics/looker_studio_datasources/power_hours_top3.csv\n",
    "!git add analytics/looker_studio_datasources/rain_uplift_by_sensor.csv\n",
    "!git add analytics/looker_studio_datasources/counts_by_hour.csv\n",
    "!git add analytics/looker_studio_datasources/sensors_lookup.csv\n",
    "!git add notebooks/02_clean_join_geo.ipynb notebooks/03_weather_merge.ipynb notebooks/04_features_kpis.ipynb\n",
    "!git commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\n",
    "!git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce08edd-bc2e-4d83-9014-47a842994fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main c9badb9] feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\n",
      " 9 files changed, 83818 insertions(+), 3 deletions(-)\n",
      " create mode 100644 analytics/looker_studio_datasources/counts_by_hour.csv\n",
      " create mode 100644 analytics/looker_studio_datasources/daily_totals.csv\n",
      " create mode 100644 analytics/looker_studio_datasources/heatmap_weekday_hour.csv\n",
      " create mode 100644 analytics/looker_studio_datasources/power_hours_top3.csv\n",
      " create mode 100644 analytics/looker_studio_datasources/rain_uplift_by_sensor.csv\n",
      " create mode 100644 analytics/looker_studio_datasources/sensors_lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/RajPoo7/melbourne-foot-traffic-marketing.git\n",
      "   864509a..c9badb9  main -> main\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "# 1) Go to the repo root (no matter where the notebook lives)\n",
    "cd \"$(git rev-parse --show-toplevel)\"\n",
    "\n",
    "# 2) Stage the CSV exports + the three notebooks\n",
    "git add \\\n",
    "  analytics/looker_studio_datasources/daily_totals.csv \\\n",
    "  analytics/looker_studio_datasources/heatmap_weekday_hour.csv \\\n",
    "  analytics/looker_studio_datasources/power_hours_top3.csv \\\n",
    "  analytics/looker_studio_datasources/rain_uplift_by_sensor.csv \\\n",
    "  analytics/looker_studio_datasources/counts_by_hour.csv \\\n",
    "  analytics/looker_studio_datasources/sensors_lookup.csv \\\n",
    "  notebooks/02_clean_join_geo.ipynb \\\n",
    "  notebooks/03_weather_merge.ipynb \\\n",
    "  notebooks/04_features_kpis.ipynb\n",
    "\n",
    "# 3) Commit (OK if it says \"nothing to commit\")\n",
    "git commit -m \"feat: KPIs & exports for dashboard (daily_totals, heatmap_weekday_hour, power_hours_top3, rain_uplift_by_sensor, counts_by_hour, sensors_lookup)\"\n",
    "\n",
    "# 4) Push to GitHub\n",
    "git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b63b51b1-4667-4c27-a419-fc7974b3b671",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2863332803.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcd \"$(git rev-parse --show-toplevel)\"   # jump to your repo root\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cd \"$(git rev-parse --show-toplevel)\"   # jump to your repo root\n",
    "git status -s                           # quick check of changes\n",
    "git add analytics/looker_studio_datasources/*.csv notebooks/*.ipynb README.md\n",
    "git commit -m \"checkpoint: end of day – data exports + notebooks saved\"\n",
    "git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75505f-077e-4588-b263-d6ec5a4832fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
